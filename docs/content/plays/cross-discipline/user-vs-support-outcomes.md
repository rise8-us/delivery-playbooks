# Supporting Outcomes vs. User-Facing Outcomes: Understanding the Difference at Rise8

## Why is this Distinction Important for Rise8?

An analogy we often use is: **"We don't want to build a beautiful bridge to nowhere."** This captures a core concern – delivering amazing internal value (like a perfect developer experience for our teams) is valuable, but if it doesn't *ultimately contribute to the mission* (a User-Facing Outcome), we have to question its true purpose. While we strive to build the "best possible bridge" – efficient and effective infrastructure (a Supporting Outcome)  – we must always ensure it leads somewhere meaningful. This is why, at Rise8, we recognize the importance of both Supporting and User-Facing Outcomes.

Understanding this distinction is **critical for *all* Risers** because it directly impacts how we:

*   **Focus on Delivering Real Mission Impact:**  This distinction ensures we're always prioritizing solutions that ultimately benefit our end users and advance their missions. It keeps us laser-focused on our core purpose: making a tangible, positive difference in the world through software.
*   **Prioritize Value Creation:** By clearly separating these outcome types, we can better prioritize work for maximum overall value. We understand that Supporting Outcomes are valuable *enablers*, but **User-Facing Outcomes are the ultimate drivers of mission success**.
*   **Maintain a High Standard of Quality:** By rigorously defining and reviewing outcomes, we uphold a high bar for all Rise8 work. This commitment benefits our clients, strengthens our reputation, and provides valuable, shareable examples of impactful outcomes for continuous learning and improvement.
*   **Drive Hypothesis-Driven Development:** Thinking in terms of outcomes encourages a hypothesis-driven approach. We're not just building features; we're running experiments to validate assumptions about how to create specific, measurable changes in user behavior or system performance that directly drive mission impact.
*   **Communicate Value Effectively:** Clearly articulating the difference between Supporting and User-Facing Outcomes allows us to effectively communicate the *full* value of our work to clients and stakeholders. We can demonstrate how our internal improvements (Supporting Outcomes) directly and measurably contribute to our ability to deliver impactful, user-centric solutions (User-Facing Outcomes) that achieve mission objectives.


## What are they?

At Rise8, we categorize Outcomes into two key types: **Supporting** and **User-Facing**. Understanding the difference is essential for all Risers to ensure we are effectively driving mission impact and delivering real value.

**User-Facing Outcomes:** These outcomes are focused on making a positive difference in the lives of our end users and/or their mission. This includes warfighters, veterans, veteran caretakers, civilians, and operators – the individuals who ultimately use the systems and products we build. User-Facing Outcomes are about achieving a measurable change in user behavior or system interaction that directly benefits these end users or their missions. It’s about direct, tangible impact on their world.

**Supporting Outcomes:** These outcomes focus on improving our internal capabilities and operations. They are achievements that enable us to deliver User-Facing Outcomes more effectively in the future. Supporting Outcomes create value for internal teams – often development teams or platform teams – by streamlining processes, enhancing infrastructure, or developing new internal capabilities. They are critical enablers, but they are not the direct, end-user-focused value we ultimately strive to deliver.

### Key Analogy:

*   **User-Facing Outcome:** The car gets the customer to their destination faster and more comfortably. (Directly benefits the end user - the driver/passenger)
*   **Supporting Outcome:** We improve our factory's efficiency by 20% so we can build cars faster. (Benefits the internal team/organization, enabling us to build more cars, but doesn't directly improve the car itself for the user in this specific outcome).

### User Outcome Examples

| Problem Example                                                                                                                            | Output                                                                                                                                                                                                                            | Outcome + Measure                                                                                                                                                                                                                                                                                                                                                                                                                      | Impact + Measure                                                                                                                                                                                                                                                                                                                                                                                                                       |
| :----------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [335](https://employees.rise8.us/outcomes?outcome_id=335) - Manual verification of veteran eligibility for Wounded Warrior Project programs was time-consuming, delaying access to critical resources. | LHDI Marmoset: Integrated Veteran Service History and Eligibility API with Wounded Warrior Project's online registration process. Automated eligibility verification based on service history, eliminating manual steps.                  | Automated eligibility verification based on service history, eliminating manual steps. <br><br> **Measure: Quantitatively** <br> 5,340 API calls across /status, /service_history, /disability_rating endpoints, indicating utilization. 37% of warriors use the API option, with 87% auto-approved. Reduction in contact resolution time from 10 to 5 days, indicating increased efficiency and faster program access. | Improved access to crucial support services for wounded warriors, demonstrated by serving 670 unique veterans. <br><br> **Measured: Quantitatively** <br> Reduction in contact resolution time from 10 to 5 days, indicating increased efficiency and faster program access. |
| [359](https://employees.rise8.us/outcomes?outcome_id=359) - AOCs cannot make ATOs at the scale required to support a modern conflict with potentially thousands of manned and autonomous systems      | Improve ATO creation performance through reducing duplicate calls, batch operations, more efficient service classes, etc. Users can now produce ATOs of 25,000 missions without the system crashing. This give users the capability needed to plan and execute MTW (Major Theater War). | Users can now produce ATOs of 25,000 missions without the system crashing. This give users the capability needed to plan and execute MTW (Major Theater War). <br><br> **Measured: Quantitatively** <br> Timed performance test, One user can create an ATO in ~20 minutes, while two users producing ATOs simultaneously can produce their ATOs in ~25 minutes | AOCs w/ KRADOS adoption are capable of producing ATOs that are used to plan and execute air battle plans of any conceivable scale against any threat. <br><br> **Measured: Quantitatively** <br> Timed performance test, One user can create an ATO in ~20 minutes, while two users producing ATOs simultaneously can produce their ATOs in ~25 minutes |
| [179](https://employees.rise8.us/outcomes?outcome_id=179) - The 18th Space Defense Combat Squadron was struggling to effectively assign sensor units with tasks to meaningfully achieve Space Domain Awareness | The Malibu team worked with the 18th to iteratively build a Mission Type Orders (MTO) workflow in Relay Tasks The 18th SDCS now uses Relay Tasks to build Mission Type Orders, assign them to sensor units, monitor the acknowledgement and completion of the orders, and assess their effectiveness. Previously this process was done via SPADOC, phone, and email. Assessments were not happening at all | The 18th SDCS now uses Relay Tasks to build Mission Type Orders, assign them to sensor units, monitor the acknowledgement and completion of the orders, and assess their effectiveness. Previously this process was done via SPADOC, phone, and email. Assessments were not happening at all <br><br> **Measured: Quantitatively** <br> Since launch of the MTO MVP in early August 2023, there are 57 users in Relay Tasks with the MTO Manager role and an observed 650+ MTOs that have been created in the app in production. The 18th uses the tool daily in operations | The 18th can more effectively achieve their mission of Space Domain Awareness by having a centralized location for managing taskings and a better tasking format. This gives the 18th a more holistic sense of the objects in orbit to protect our assets and track adversaries <br><br> **Measured: Qualitatively** <br> Users reported that this workflow will "revolutionize sensor tasking" and enable the 18th to more deeply understand the purpose and intentions behind space objects from non-friendlies which has become a critical focus in recent years. MTOs are brand new so more quantitative metrics will follow |

### Support Outcome Examples

| Problem Example                                                                                                                            | Output                                                                                                                                                                                                                            | Outcome + Measure                                                                                                                                                                                                                                                           | Impact + Measure                                                                                                                                                                                                                                                                                                                                             |
| :----------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [314](https://employees.rise8.us/outcomes?outcome_id=314) - The “Observability” team was on the path to deploy an application that delivered no new functionality to customers.                 | We gained leadership approval to halt development for the application due to redundancy based on our research findings.                                                                                                                    | The observability team now knows to confirm users problems/needs before starting development. <br><br> **Measured: Qualitatively** <br> The leadership team agreed the Superset application was not needed. After a move to Grafana all required functionality was provided and is in production today. "This is a great win" - UP PLM | Removal of redundant work saved almost 1,000 dev hrs of unnecessary work like: 1) fix vulnerabilities required to meet ORA % rating and 2) upkeep technical debt due to new version release. UP team has also gained a new example to show new teams why our app team support is valuable. <br><br> **Measured: Quantitatively** <br> We estimated the time to solve vulnerabilities based on previous hours spent by developers. This came out to 1,000 hours in developer time. |
| [337](https://employees.rise8.us/outcomes?outcome_id=337) - We need a government ATO to accept users on a production environment. It would've taken months to quarters to get an ATO for G8way. | For production, we set up containerized applications on AWS IaaS. Our containers deployed within Nebula boundary had 0 crit/high vulns. It would've taken months and thousands of dollars to get independent audits from 3PAs that the Space AO wanted us to do. We communicated the risks to our stakeholders and they quickly rallied the platform team to support us in moving under their ATO boundary so we could get to prod in 3 weeks. | It would've taken months and thousands of dollars to get independent audits from 3PAs that the Space AO wanted us to do. We communicated the risks to our stakeholders and they quickly rallied the platform team to support us in moving under their ATO boundary so we could get to prod in 3 weeks. <br><br> **Measured: Qualitatively** <br> Nebula said we could move into their boundary on Jan 6. We got the ATO and green light to prod on Jan 24. Quotes from the Cole Presley at Space AO said the typical timeframe for an ATO was 3-4 months. | Without a prod environment, we couldn't even store CUI data for a real user pilot. Now we're negotiating with Julia on a date for our pilot with our space industry instead of working on cybersecurity reviews and documentation. <br><br> **Measured: Qualitatively** <br> NA. Our first demo with Julia was a success last week and she said she'd reach out to LSPs to get some initial feedback this week. Setting up a pilot in Q1.                                   |
| [296](https://employees.rise8.us/outcomes?outcome_id=296) - The tenant application team needed a new feature (replication streaming) only available in the Postgres Operator version 3.0.             | An upgrade was made to the Postgres Operator to allow for the application team (ATLAS) to use replication streaming for their db's.                                                                                             | The application team had a better database solution for their backup and recovery in swapping from 'green' to 'blue'. <br><br> **Measured: Quantitatively** <br> Without the data replication streaming the application would have lost ~5 minutes worth of data in the event of a failover. | The application team had a better failover database option which would allow them to reduce data loss that would have occurred previously. <br><br> **Measured: Quantitatively** <br> Data loss was reduced from 5 minutes to no time at all.                                                                          |

## How to Differentiate and Apply These Concepts in Your Work

Here's how all Risers can apply this understanding in their day-to-day work:

*   **When Defining Outcomes, Ask the "End User Question":** For every proposed outcome, ask: "Will achieving this outcome directly change the behavior or experience of our end users (warfighters, veterans, citizens, etc.) in a positive way?" If the answer is "no," then consider if it's a Supporting Outcome, and ensure you can clearly articulate how it will enable future User-Facing Outcomes.
*   **Anchor Problem Statements to User/Mission Needs:** Ensure your problem statements clearly articulate a challenge or pain point experienced by end users or a mission need. Don’t stop with just saving time, drive into the underlying actions and how they impact the mission. This provides a solid foundation for defining both types of outcomes and ensures they are always grounded in real-world impact.
*   **Be Specific and Measurable (For Both Outcome Types):** Regardless of whether it's a Supporting or User-Facing Outcome, strive to make it specific and measurable. Define clear metrics and targets to validate whether the outcome has been achieved. For Supporting Outcomes, measure improvements in internal processes or capabilities. For User-Facing Outcomes, measure changes in user behavior or system performance as experienced by end users.
*   **Track and Validate Both Types of Outcomes:** Recognize the value of both Supporting and User-Facing Outcomes and track their achievement. Use data and metrics to validate your hypotheses and learn from both successes and failures in delivering both types of value. This data-driven approach is key to continuous improvement.
*   **For Platform/Enabling Teams: Emphasize the User-Facing Connection:** If you are working on platform or enabling services, be especially mindful of articulating the link between your Supporting Outcomes and the User-Facing Outcomes they enable. How does your platform capability ultimately translate to a better experience or outcome for the end user? Make this connection explicit and measurable.

### Remember User Outcomes Are a Team Sport

*   **For Platform/Enabling Teams: Take Credit!** You enabled those user outcomes that teams deploying on your platform created. Find ways to get inside the feedback loops where your teams are reporting wins and reach out! Consider using a template like the following:

    ```
    Hey [dev team person]! Don't think I have met you yet, I'm the [role] for the [team].
    I was reading through the cool  <ie: sprint demo deck, newsletter, release notes, slack post, etc> from <time>. Would you be open to 2️⃣  questions I had about it?

    For some extra context: we on P often feel disconnected from the value dev teams are creating for users. I'd like to bring back some wins to our team to keep us connected to the end value your team is trying to provide.

    1️⃣ I translated your slide a bit, does this make sense to you?
    Problem: <replace>
    Thing Built: <replace>
    Change in User Behavior: <replace>
    Measured by: <replace>
    Impact on Vet/Caretaker Lives: <replace> <usually need more info here, use ❓ to signal a follow up>
    Measured by: <replace> <usually need more info here, use ❓ to signal a follow up>

    2️⃣  Did you have any pains deploying this release or any feedback we can take back to our folks on Platform (Enablement / SecRel / Ops)  to make the next feature even easier❓
    ```

*   **For Delivering Dev Teams: Share Credit!** You were able to go to prod and your app is hosted through a lot of blood, sweat, and tears of other teams. Tag them on your wins!
